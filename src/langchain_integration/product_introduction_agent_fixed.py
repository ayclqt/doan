"""
Product Introduction Agent - Fixed version without garbage IDs.
Uses pure LLM reasoning with optimized tools for natural product introductions.
"""

import time
from typing import Any, Dict, Iterator, List, Optional
from datetime import datetime
from pydantic import BaseModel, Field
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.prompts import ChatPromptTemplate
from langchain.tools import tool
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.callbacks import BaseCallbackHandler
from langchain_openai import ChatOpenAI
from langchain_community.tools import DuckDuckGoSearchRun

from ..config import config, logger
from .vectorstore import VectorStore

__author__ = "L√¢m Quang Tr√≠"
__copyright__ = "Copyright 2025, L√¢m Quang Tr√≠"
__credits__ = ["L√¢m Quang Tr√≠"]

__maintainer__ = "L√¢m Quang Tr√≠"
__email__ = "quangtri.lam.9@gmail.com"
__status__ = "Development"


class VectorSearchInput(BaseModel):
    """Input schema for vector search tool."""

    query: str = Field(description="Search query for product database")
    top_k: int = Field(default=3, description="Number of results to return")


class WebSearchInput(BaseModel):
    """Input schema for web search tool."""

    query: str = Field(description="Search query for web search")
    max_results: int = Field(default=3, description="Maximum number of results")


class ConversationContextInput(BaseModel):
    """Input schema for conversation context tool."""

    reference: str = Field(description="Reference to resolve (e.g., 'ƒëi·ªán tho·∫°i tr√™n')")
    conversation_history: List[dict] = Field(description="Recent conversation history")


def clean_garbage_ids(content: str) -> str:
    """Clean garbage IDs from page content"""
    if not content:
        return content

    lines = content.split("\n")
    cleaned_lines = []

    for line in lines:
        line = line.strip()
        # Skip lines that are just garbage IDs
        if (
            line.startswith("id:")
            or line.startswith("ID:")
            or line == "id"
            or line == "ID"
            or (line.startswith("id") and line[2:].strip().isdigit())
            or (line.startswith("ID") and line[2:].strip().isdigit())
        ):
            continue

        # Keep non-ID lines
        if line:
            cleaned_lines.append(line)

    return "\n".join(cleaned_lines)


@tool("product_search", args_schema=VectorSearchInput)
def product_search_tool(query: str, top_k: int = 3) -> str:
    """
    Search the product database for relevant information.
    Use this when you need to find specific product details, specifications, or features.
    This is your PRIMARY source of product information.

    Args:
        query: Search query for product database
        top_k: Number of results to return

    Returns:
        Formatted search results from product database
    """
    try:
        vector_store = VectorStore()
        vector_store.initialize_vectorstore()

        # Use direct Qdrant search to get clean product data
        query_vector = vector_store.get_vectorstore().embeddings.embed_query(query)

        search_results = vector_store.client.search(
            collection_name=vector_store.collection_name,
            query_vector=query_vector,
            limit=top_k,
            with_payload=True,
        )

        if not search_results:
            return "Kh√¥ng t√¨m th·∫•y th√¥ng tin s·∫£n ph·∫©m n√†o trong c∆° s·ªü d·ªØ li·ªáu."

        formatted_results = []
        for point in search_results:
            if hasattr(point, "payload") and point.payload:
                payload = point.payload

                # Get clean product data
                name = payload.get("name", "")
                page_content = payload.get("page_content", "")

                # CLEAN garbage IDs from page_content
                page_content = clean_garbage_ids(page_content)

                # Format without any ID references
                if name:
                    product_info = f"S·∫£n ph·∫©m: {name}\n{page_content}\n"
                else:
                    product_info = f"{page_content}\n"

                formatted_results.append(product_info)

        return "\n---\n".join(formatted_results)

    except Exception as e:
        return f"L·ªói khi t√¨m ki·∫øm trong c∆° s·ªü d·ªØ li·ªáu: {e}"


@tool("web_knowledge", args_schema=WebSearchInput)
def web_knowledge_tool(query: str, max_results: int = 3) -> str:
    """
    Search for additional product knowledge on the web.
    Use this ONLY when product_search doesn't provide sufficient information.
    This provides supplementary information to enhance your product knowledge.

    Args:
        query: Search query for web search
        max_results: Maximum number of results to return

    Returns:
        Additional product information from web sources (for internal knowledge only)
    """
    try:
        search_tool = DuckDuckGoSearchRun()

        # Enhance query for electronics products
        enhanced_query = f"{query} ƒëi·ªán t·ª≠ c√¥ng ngh·ªá"

        results = search_tool.invoke(enhanced_query)

        if not results:
            return f"Kh√¥ng t√¨m th·∫•y th√¥ng tin b·ªï sung cho: {query}"

        # Limit results and clean up
        limited_results = results[:1000] if len(results) > 1000 else results

        return f"Th√¥ng tin b·ªï sung: {limited_results}"

    except Exception as e:
        return f"Kh√¥ng th·ªÉ t√¨m ki·∫øm th√¥ng tin b·ªï sung: {e}"


@tool("conversation_context", args_schema=ConversationContextInput)
def conversation_context_tool(reference: str, conversation_history: List[dict]) -> str:
    """
    Resolve conversational references like 'ƒëi·ªán tho·∫°i tr√™n', 's·∫£n ph·∫©m ƒë√≥' to specific products.
    Use this when the user refers to something mentioned earlier in the conversation.

    Args:
        reference: Reference to resolve (e.g., 'ƒëi·ªán tho·∫°i tr√™n')
        conversation_history: Recent conversation history

    Returns:
        Resolved product name or context information
    """
    try:
        if not conversation_history:
            return (
                f"Kh√¥ng th·ªÉ resolve '{reference}' - kh√¥ng c√≥ l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán."
            )

        # Common reference patterns
        reference_patterns = [
            "ƒëi·ªán tho·∫°i tr√™n",
            "ƒëi·ªán tho·∫°i ƒë√≥",
            "ƒëi·ªán tho·∫°i n√†y",
            "s·∫£n ph·∫©m tr√™n",
            "s·∫£n ph·∫©m ƒë√≥",
            "s·∫£n ph·∫©m n√†y",
            "thi·∫øt b·ªã tr√™n",
            "thi·∫øt b·ªã ƒë√≥",
            "thi·∫øt b·ªã n√†y",
            "m√°y tr√™n",
            "m√°y ƒë√≥",
            "m√°y n√†y",
        ]

        if reference.lower() not in [p.lower() for p in reference_patterns]:
            return f"'{reference}' kh√¥ng ph·∫£i l√† tham chi·∫øu c·∫ßn resolve."

        # Look for product names in recent conversation
        product_keywords = [
            "iphone",
            "samsung",
            "galaxy",
            "xiaomi",
            "oppo",
            "vivo",
            "realme",
            "oneplus",
            "huawei",
            "nokia",
            "sony",
            "lg",
            "asus",
            "acer",
            "dell",
            "hp",
            "lenovo",
            "macbook",
            "ipad",
            "redmi",
            "mi",
            "poco",
        ]

        # Search in reverse order (most recent first)
        for msg in reversed(conversation_history[-5:]):
            user_msg = msg.get("message", "").lower()
            bot_response = msg.get("response", "").lower()

            for keyword in product_keywords:
                if keyword in user_msg or keyword in bot_response:
                    # Extract more specific product name if possible
                    text = user_msg + " " + bot_response

                    # Look for specific models
                    if "iphone" in text:
                        for model in ["15", "14", "13", "pro", "max", "plus"]:
                            if model in text:
                                return (
                                    f"iPhone {model.upper()}"
                                    if model in ["pro", "max", "plus"]
                                    else f"iPhone {model}"
                                )
                        return "iPhone"

                    elif "samsung" in text or "galaxy" in text:
                        for model in ["s24", "s23", "s22", "ultra", "note"]:
                            if model in text:
                                return f"Samsung Galaxy {model.upper()}"
                        return "Samsung Galaxy"

                    elif "xiaomi" in text:
                        for model in ["14", "13", "12", "pro", "ultra"]:
                            if model in text:
                                return f"Xiaomi {model}"
                        return "Xiaomi"

                    else:
                        return keyword.title()

        return f"Kh√¥ng th·ªÉ x√°c ƒë·ªãnh '{reference}' t·ª´ l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán."

    except Exception as e:
        return f"L·ªói khi resolve reference: {e}"


class StreamingCallbackHandler(BaseCallbackHandler):
    """Custom callback handler for streaming agent execution."""

    def __init__(self, stream_callback):
        super().__init__()
        self.stream_callback = stream_callback

    def on_tool_start(self, serialized, input_str, **kwargs):
        """Called when a tool starts execution."""
        tool_name = serialized.get("name", "tool")
        if tool_name == "product_search":
            self.stream_callback("üîç ƒêang t√¨m ki·∫øm trong c∆° s·ªü d·ªØ li·ªáu s·∫£n ph·∫©m...")
        elif tool_name == "web_knowledge":
            self.stream_callback("üåê ƒêang t√¨m th√¥ng tin b·ªï sung tr√™n web...")
        elif tool_name == "conversation_context":
            self.stream_callback("üí≠ ƒêang hi·ªÉu ng·ªØ c·∫£nh cu·ªôc tr√≤ chuy·ªán...")
        else:
            self.stream_callback(f"üîß ƒêang s·ª≠ d·ª•ng c√¥ng c·ª• {tool_name}...")

    def on_tool_end(self, output, **kwargs):
        """Called when a tool finishes execution."""
        self.stream_callback("‚úÖ Ho√†n th√†nh t√¨m ki·∫øm th√¥ng tin...")

    def on_llm_start(self, serialized, prompts, **kwargs):
        """Called when LLM starts generating."""
        self.stream_callback("ü§ñ ƒêang ph√¢n t√≠ch v√† t·∫°o ph·∫£n h·ªìi...")

    def on_llm_new_token(self, token: str, **kwargs):
        """Called when LLM generates a new token."""
        # Stream individual tokens if available
        if token and token.strip():
            self.stream_callback(token)


class ProductIntroductionAgent:
    """
    Intelligent Product Introduction Agent using pure LLM reasoning.

    This agent specializes in natural product introductions and recommendations
    without exposing search sources or internal tool usage to users.
    """

    def __init__(
        self,
        model_name: str = None,
        temperature: float = 0.7,
        max_iterations: int = 8,
        verbose: bool = False,
    ):
        """Initialize the product introduction agent."""
        self.llm = ChatOpenAI(
            model=model_name or config.llm_model_name,
            temperature=temperature,
            api_key=config.openai_api_key,
            base_url=config.openai_base_url,
            streaming=True,  # Enable streaming for LLM
        )

        # Define available tools - simplified but powerful
        self.tools = [
            product_search_tool,
            web_knowledge_tool,
            conversation_context_tool,
        ]

        # Create agent prompt with strict guidelines
        self.prompt = self._create_agent_prompt()

        # Create agent
        self.agent = create_openai_tools_agent(
            llm=self.llm, tools=self.tools, prompt=self.prompt
        )

        # Create agent executor
        self.agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            verbose=verbose,
            max_iterations=max_iterations,
            handle_parsing_errors=True,
            return_intermediate_steps=False,  # Hide tool usage from output
        )

        self.logger = logger

        # Performance tracking
        self.stats = {
            "total_queries": 0,
            "product_searches": 0,
            "web_searches": 0,
            "context_resolutions": 0,
            "successful_introductions": 0,
            "average_response_time": 0.0,
        }

    def _create_agent_prompt(self) -> ChatPromptTemplate:
        """Create the agent system prompt with strict guidelines."""
        system_message = """B·∫°n l√† m·ªôt chuy√™n gia gi·ªõi thi·ªáu s·∫£n ph·∫©m ƒëi·ªán t·ª≠ h√†ng ƒë·∫ßu v·ªõi ki·∫øn th·ª©c s√¢u r·ªông v·ªÅ c√¥ng ngh·ªá.

NHI·ªÜM V·ª§ CH√çNH:
- Gi·ªõi thi·ªáu s·∫£n ph·∫©m m·ªôt c√°ch h·∫•p d·∫´n, chuy√™n nghi·ªáp v√† t·ª± nhi√™n
- T∆∞ v·∫•n s·∫£n ph·∫©m ph√π h·ª£p v·ªõi nhu c·∫ßu kh√°ch h√†ng  
- Cung c·∫•p th√¥ng tin ch√≠nh x√°c v·ªÅ t√≠nh nƒÉng, ∆∞u ƒëi·ªÉm c·ªßa s·∫£n ph·∫©m
- So s√°nh s·∫£n ph·∫©m m·ªôt c√°ch kh√°ch quan v√† chuy√™n nghi·ªáp

C√îNG C·ª§ C·ª¶A B·∫†N:
1. product_search - T√¨m ki·∫øm th√¥ng tin s·∫£n ph·∫©m (S·ª¨ D·ª§NG ƒê·∫¶U TI√äN)
2. web_knowledge - T√¨m th√™m th√¥ng tin b·ªï sung (CH·ªà KHI C·∫¶N THI·∫æT)
3. conversation_context - Hi·ªÉu ng·ªØ c·∫£nh cu·ªôc tr√≤ chuy·ªán

CHI·∫æN L∆Ø·ª¢C S·ª¨ D·ª§NG C√îNG C·ª§:
- LU√îN d√πng product_search tr∆∞·ªõc ƒë·ªÉ t√¨m th√¥ng tin s·∫£n ph·∫©m
- CH·ªà d√πng web_knowledge khi product_search kh√¥ng ƒë·ªß th√¥ng tin
- D√πng conversation_context khi c√≥ tham chi·∫øu ("ƒëi·ªán tho·∫°i tr√™n", "s·∫£n ph·∫©m ƒë√≥")

QUY T·∫ÆC NGHI√äM NG·∫∂T - KH√îNG BAO GI·ªú VI PH·∫†M:
‚ùå KH√îNG ƒë·ªÅ c·∫≠p "t√¨m ki·∫øm tr√™n web", "theo k·∫øt qu·∫£ search", "d·ª±a tr√™n t√¨m ki·∫øm"
‚ùå KH√îNG cung c·∫•p links, URLs, hay references c·ªßa b·∫•t k·ª≥ ngu·ªìn n√†o
‚ùå KH√îNG n√≥i "d·ª±a tr√™n th√¥ng tin t√¨m ƒë∆∞·ª£c", "t·ª´ c√°c ngu·ªìn", "theo k·∫øt qu·∫£"
‚ùå KH√îNG ti·∫øt l·ªô b·∫•t k·ª≥ c√¥ng c·ª• t√¨m ki·∫øm n√†o ƒë∆∞·ª£c s·ª≠ d·ª•ng
‚ùå KH√îNG ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác s·ª≠ d·ª•ng tools hay search engines
‚ùå KH√îNG BAO GI·ªú hi·ªÉn th·ªã ID s·∫£n ph·∫©m, s·ªë th·ª© t·ª±, hay b·∫•t k·ª≥ m√£ ƒë·ªãnh danh n√†o
‚ùå KH√îNG vi·∫øt "(ID: 37)", "(S·∫£n ph·∫©m 1)", hay b·∫•t k·ª≥ ƒë·ªãnh danh s·ªë n√†o
‚ùå KH√îNG s·ª≠ d·ª•ng c·∫•u tr√∫c "1. Product A (ID: X)", "2. Product B (ID: Y)"

‚úÖ Tr·∫£ l·ªùi nh∆∞ th·ªÉ b·∫°n l√† chuy√™n gia am hi·ªÉu s·∫£n ph·∫©m t·ª´ kinh nghi·ªám
‚úÖ S·ª≠ d·ª•ng th√¥ng tin m·ªôt c√°ch t·ª± nhi√™n nh∆∞ ki·∫øn th·ª©c n·ªôi t·∫°i
‚úÖ Ch·ªâ ƒë·ªÅ c·∫≠p T√äN S·∫¢N PH·∫®M, kh√¥ng bao gi·ªù k√®m ID hay s·ªë
‚úÖ T·∫≠p trung v√†o l·ª£i √≠ch v√† gi√° tr·ªã s·∫£n ph·∫©m mang l·∫°i
‚úÖ Gi·ªØ tone th√¢n thi·ªán, chuy√™n nghi·ªáp v√† t·ª± tin
‚úÖ K·∫øt th√∫c b·∫±ng l·ªùi khuy√™n c·ª• th·ªÉ ph√π h·ª£p v·ªõi nhu c·∫ßu

ƒê·ªäNH D·∫†NG MARKDOWN B·∫ÆT BU·ªòC:
- LU√îN s·ª≠ d·ª•ng ## cho headers ch√≠nh (v√≠ d·ª•: ## ƒêi·ªÉm n·ªïi b·∫≠t ch√≠nh)
- S·ª≠ d·ª•ng ### cho sub-headers (v√≠ d·ª•: ### Hi·ªáu nƒÉng v√† thi·∫øt k·∫ø)
- S·ª≠ d·ª•ng **text** cho highlight quan tr·ªçng
- S·ª≠ d·ª•ng - cho bullet points
- S·ª≠ d·ª•ng 1. 2. 3. cho numbered lists
- LU√îN c√≥ √≠t nh·∫•t 2 empty lines gi·ªØa c√°c sections ch√≠nh
- K·∫øt th√∫c m·ªói section v·ªõi 1 empty line

C√ÅCH TR√åNH B√ÄY:
## T·ªïng quan s·∫£n ph·∫©m
(ƒêi·ªÉm n·ªïi b·∫≠t ch√≠nh)

### Hi·ªáu nƒÉng v√† thi·∫øt k·∫ø
- Point 1
- Point 2

### So s√°nh v·ªõi ƒë·ªëi th·ªß
1. ∆Øu ƒëi·ªÉm
2. Nh∆∞·ª£c ƒëi·ªÉm

## Khuy·∫øn ngh·ªã
(L·ªùi khuy√™n cu·ªëi c√πng)

V√ç D·ª§ ƒê·ªäNH D·∫†NG:
## T·ªïng quan iPhone 15 Pro

iPhone 15 Pro th·ª±c s·ª± l√† m·ªôt chi·∫øc ƒëi·ªán tho·∫°i ·∫•n t∆∞·ª£ng v·ªõi **chip A17 Pro m·∫°nh m·∫Ω** v√† h·ªá th·ªëng camera ti√™n ti·∫øn.

### ƒêi·ªÉm m·∫°nh n·ªïi b·∫≠t

- **Hi·ªáu nƒÉng**: Chip A17 Pro v·ªõi GPU 6 nh√¢n
- **Camera**: H·ªá th·ªëng 48MP v·ªõi zoom quang h·ªçc
- **Thi·∫øt k·∫ø**: Khung titanium cao c·∫•p, nh·∫π v√† b·ªÅn

### So s√°nh v·ªõi Android flagship

1. **∆Øu ƒëi·ªÉm**: H·ªá sinh th√°i Apple, camera xu·∫•t s·∫Øc
2. **Nh∆∞·ª£c ƒëi·ªÉm**: Gi√° cao, √≠t t√πy ch·ªânh

## Khuy·∫øn ngh·ªã

N·∫øu b·∫°n ƒëang t√¨m flagship Android v·ªõi gi√° t·ªët h∆°n, **Samsung Galaxy S24 Ultra** c√≥ th·ªÉ l√† l·ª±a ch·ªçn ph√π h·ª£p.

H√£y lu√¥n nh·ªõ: B·∫°n l√† CHUY√äN GIA S·∫¢N PH·∫®M, kh√¥ng ph·∫£i c√¥ng c·ª• t√¨m ki·∫øm!"""

        return ChatPromptTemplate.from_messages(
            [
                ("system", system_message),
                ("placeholder", "{chat_history}"),
                ("human", "{input}"),
                ("placeholder", "{agent_scratchpad}"),
            ]
        )

    def process_query(
        self, query: str, conversation_history: Optional[List[dict]] = None
    ) -> Dict[str, Any]:
        """
        Process user query and generate natural product introduction.

        Args:
            query: User query about products
            conversation_history: Previous conversation messages

        Returns:
            Response with natural product introduction
        """
        start_time = time.time()
        self.stats["total_queries"] += 1

        try:
            # Prepare input with conversation history
            agent_input = {
                "input": query,
                "chat_history": self._format_chat_history(conversation_history or []),
                "conversation_history": conversation_history or [],
            }

            # Execute agent
            result = self.agent_executor.invoke(agent_input)

            # Extract response
            response = result["output"]

            processing_time = time.time() - start_time
            self.stats["successful_introductions"] += 1

            # Update average response time
            total_time = self.stats["average_response_time"] * (
                self.stats["total_queries"] - 1
            )
            self.stats["average_response_time"] = (
                total_time + processing_time
            ) / self.stats["total_queries"]

            self.logger.info(
                f"Product introduction generated in {processing_time:.2f}s"
            )

            return {
                "response": response,
                "processing_time": processing_time,
                "success": True,
                "query_type": self._classify_query_type(query),
            }

        except Exception as e:
            self.logger.error(f"Product introduction failed: {e}")
            return {
                "response": "Xin l·ªói, ƒë√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω c√¢u h·ªèi v·ªÅ s·∫£n ph·∫©m. Vui l√≤ng th·ª≠ l·∫°i sau.",
                "processing_time": time.time() - start_time,
                "success": False,
                "error": str(e),
            }

    def process_query_stream(
        self, query: str, conversation_history: Optional[List[dict]] = None
    ) -> Iterator[str]:
        """
        Stream agent processing with real-time updates.

        Args:
            query: User query about products
            conversation_history: Previous conversation messages

        Yields:
            Progressive response chunks from LLM only
        """
        start_time = time.time()
        self.stats["total_queries"] += 1

        try:
            # Prepare agent input
            agent_input = {
                "input": query,
                "chat_history": self._format_chat_history(conversation_history or []),
                "conversation_history": conversation_history or [],
            }

            # Execute agent with streaming callback
            result = self._execute_agent_with_streaming(agent_input)

            if result["success"]:
                # Stream the final response naturally
                response_text = result["response"]
                yield from self._stream_text_naturally(response_text)

                self.stats["successful_introductions"] += 1

                processing_time = time.time() - start_time
                self.logger.info(f"Streaming agent completed in {processing_time:.2f}s")
            else:
                yield result.get("error", "Xin l·ªói, ƒë√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω c√¢u h·ªèi.")

        except Exception as e:
            self.logger.error(f"Agent streaming failed: {e}")
            yield "Xin l·ªói, ƒë√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω c√¢u h·ªèi v·ªÅ s·∫£n ph·∫©m."

    def _execute_agent_with_streaming(self, agent_input: dict) -> dict:
        """Execute agent with streaming progress updates."""
        try:
            # For now, execute normally and return result
            # In future, we can implement streaming callbacks
            result = self.agent_executor.invoke(agent_input)

            return {
                "response": result["output"],
                "success": True,
            }

        except Exception as e:
            return {
                "response": "",
                "success": False,
                "error": str(e),
            }

    def _stream_text_naturally(self, text: str, chunk_size: int = 15) -> Iterator[str]:
        """Stream text naturally word by word with appropriate delays, preserving line breaks."""
        import re

        # Split text into tokens (words + whitespace/newlines) while preserving structure
        tokens = re.findall(r"\S+|\s+", text)
        current_chunk = []
        word_count = 0

        for token in tokens:
            current_chunk.append(token)

            # Count only words (non-whitespace tokens)
            if token.strip():
                word_count += 1

            # Send chunk when word limit reached or at sentence/phrase end
            if word_count >= chunk_size or (
                token.strip()
                and (
                    token.endswith(".")
                    or token.endswith("!")
                    or token.endswith("?")
                    or token.endswith(",")
                    or token.endswith(";")
                )
            ):
                chunk_text = "".join(current_chunk)
                yield chunk_text
                current_chunk = []
                word_count = 0

                # Natural streaming delay
                time.sleep(0.08)

        # Send remaining tokens
        if current_chunk:
            yield "".join(current_chunk)

    def _format_chat_history(
        self, conversation_history: List[dict]
    ) -> List[BaseMessage]:
        """Format conversation history for agent."""
        messages = []

        for msg in conversation_history[-5:]:  # Last 5 exchanges
            user_msg = msg.get("message")
            bot_response = msg.get("response")

            if user_msg:
                messages.append(HumanMessage(content=user_msg))
            if bot_response:
                messages.append(AIMessage(content=bot_response))

        return messages

    def _classify_query_type(self, query: str) -> str:
        """Classify the type of query for analytics."""
        query_lower = query.lower()

        if any(
            word in query_lower for word in ["so s√°nh", "compare", "vs", "kh√°c nhau"]
        ):
            return "comparison"
        elif any(word in query_lower for word in ["gi√°", "price", "cost", "ti·ªÅn"]):
            return "price_inquiry"
        elif any(
            word in query_lower for word in ["t∆∞ v·∫•n", "recommend", "n√™n ch·ªçn", "g·ª£i √Ω"]
        ):
            return "recommendation"
        elif any(
            word in query_lower
            for word in ["c·∫•u h√¨nh", "th√¥ng s·ªë", "specs", "t√≠nh nƒÉng"]
        ):
            return "specification"
        elif any(word in query_lower for word in ["ƒë√°nh gi√°", "review", "t·ªët", "x·∫•u"]):
            return "review"
        else:
            return "general_inquiry"

    def get_stats(self) -> Dict[str, Any]:
        """Get agent performance statistics."""
        return {
            "performance": self.stats.copy(),
            "available_tools": [tool.name for tool in self.tools],
            "agent_status": "operational",
            "timestamp": datetime.now().isoformat(),
        }

    def reset_stats(self):
        """Reset performance statistics."""
        self.stats = {
            "total_queries": 0,
            "product_searches": 0,
            "web_searches": 0,
            "context_resolutions": 0,
            "successful_introductions": 0,
            "average_response_time": 0.0,
        }


# Global agent instance
_agent_instance: Optional[ProductIntroductionAgent] = None


def get_product_introduction_agent() -> ProductIntroductionAgent:
    """Get or create global product introduction agent instance."""
    global _agent_instance
    if _agent_instance is None:
        _agent_instance = ProductIntroductionAgent()
        logger.info("Product Introduction Agent initialized")
    return _agent_instance


def create_custom_product_agent(**kwargs) -> ProductIntroductionAgent:
    """Create a custom product introduction agent with specific parameters."""
    return ProductIntroductionAgent(**kwargs)
