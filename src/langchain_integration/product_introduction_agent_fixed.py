"""
Product Introduction Agent - Fixed version without garbage IDs.
Uses pure LLM reasoning with optimized tools for natural product introductions.
"""

import time
from typing import Any, Dict, Iterator, List, Optional
from datetime import datetime
from pydantic import BaseModel, Field
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.prompts import ChatPromptTemplate
from langchain.tools import tool
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.callbacks import BaseCallbackHandler
from langchain_openai import ChatOpenAI
from langchain_community.tools import DuckDuckGoSearchRun

from ..config import config, logger
from .vectorstore import VectorStore

__author__ = "LÃ¢m Quang TrÃ­"
__copyright__ = "Copyright 2025, LÃ¢m Quang TrÃ­"
__credits__ = ["LÃ¢m Quang TrÃ­"]

__maintainer__ = "LÃ¢m Quang TrÃ­"
__email__ = "quangtri.lam.9@gmail.com"
__status__ = "Development"


class VectorSearchInput(BaseModel):
    """Input schema for vector search tool."""

    query: str = Field(description="Search query for product database")
    top_k: int = Field(default=3, description="Number of results to return")


class WebSearchInput(BaseModel):
    """Input schema for web search tool."""

    query: str = Field(description="Search query for web search")
    max_results: int = Field(default=3, description="Maximum number of results")


class ConversationContextInput(BaseModel):
    """Input schema for conversation context tool."""

    reference: str = Field(description="Reference to resolve (e.g., 'Ä‘iá»‡n thoáº¡i trÃªn')")
    conversation_history: List[dict] = Field(description="Recent conversation history")


def clean_garbage_ids(content: str) -> str:
    """Clean garbage IDs from page content"""
    if not content:
        return content

    lines = content.split("\n")
    cleaned_lines = []

    for line in lines:
        line = line.strip()
        # Skip lines that are just garbage IDs
        if (
            line.startswith("id:")
            or line.startswith("ID:")
            or line == "id"
            or line == "ID"
            or (line.startswith("id") and line[2:].strip().isdigit())
            or (line.startswith("ID") and line[2:].strip().isdigit())
        ):
            continue

        # Keep non-ID lines
        if line:
            cleaned_lines.append(line)

    return "\n".join(cleaned_lines)


@tool("product_search", args_schema=VectorSearchInput)
def product_search_tool(query: str, top_k: int = 3) -> str:
    """
    Search the product database for relevant information.
    Use this when you need to find specific product details, specifications, or features.
    This is your PRIMARY source of product information.

    Args:
        query: Search query for product database
        top_k: Number of results to return

    Returns:
        Formatted search results from product database
    """
    try:
        vector_store = VectorStore()
        vector_store.initialize_vectorstore()

        # Use direct Qdrant search to get clean product data
        query_vector = vector_store.get_vectorstore().embeddings.embed_query(query)

        search_results = vector_store.client.search(
            collection_name=vector_store.collection_name,
            query_vector=query_vector,
            limit=top_k,
            with_payload=True,
        )

        if not search_results:
            return "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin sáº£n pháº©m nÃ o trong cÆ¡ sá»Ÿ dá»¯ liá»‡u."

        formatted_results = []
        for point in search_results:
            if hasattr(point, "payload") and point.payload:
                payload = point.payload

                # Get clean product data
                name = payload.get("name", "")
                page_content = payload.get("page_content", "")

                # CLEAN garbage IDs from page_content
                page_content = clean_garbage_ids(page_content)

                # Format without any ID references
                if name:
                    product_info = f"Sáº£n pháº©m: {name}\n{page_content}\n"
                else:
                    product_info = f"{page_content}\n"

                formatted_results.append(product_info)

        return "\n---\n".join(formatted_results)

    except Exception as e:
        return f"Lá»—i khi tÃ¬m kiáº¿m trong cÆ¡ sá»Ÿ dá»¯ liá»‡u: {e}"


@tool("web_knowledge", args_schema=WebSearchInput)
def web_knowledge_tool(query: str, max_results: int = 3) -> str:
    """
    Search for additional product knowledge on the web.
    Use this ONLY when product_search doesn't provide sufficient information.
    This provides supplementary information to enhance your product knowledge.

    Args:
        query: Search query for web search
        max_results: Maximum number of results to return

    Returns:
        Additional product information from web sources (for internal knowledge only)
    """
    try:
        search_tool = DuckDuckGoSearchRun()

        # Enhance query for electronics products
        enhanced_query = f"{query} Ä‘iá»‡n tá»­ cÃ´ng nghá»‡"

        results = search_tool.invoke(enhanced_query)

        if not results:
            return f"KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin bá»• sung cho: {query}"

        # Limit results and clean up
        limited_results = results[:1000] if len(results) > 1000 else results

        return f"ThÃ´ng tin bá»• sung: {limited_results}"

    except Exception as e:
        return f"KhÃ´ng thá»ƒ tÃ¬m kiáº¿m thÃ´ng tin bá»• sung: {e}"


@tool("conversation_context", args_schema=ConversationContextInput)
def conversation_context_tool(reference: str, conversation_history: List[dict]) -> str:
    """
    Resolve conversational references like 'Ä‘iá»‡n thoáº¡i trÃªn', 'sáº£n pháº©m Ä‘Ã³' to specific products.
    Use this when the user refers to something mentioned earlier in the conversation.

    Args:
        reference: Reference to resolve (e.g., 'Ä‘iá»‡n thoáº¡i trÃªn')
        conversation_history: Recent conversation history

    Returns:
        Resolved product name or context information
    """
    try:
        if not conversation_history:
            return (
                f"KhÃ´ng thá»ƒ resolve '{reference}' - khÃ´ng cÃ³ lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n."
            )

        # Common reference patterns
        reference_patterns = [
            "Ä‘iá»‡n thoáº¡i trÃªn",
            "Ä‘iá»‡n thoáº¡i Ä‘Ã³",
            "Ä‘iá»‡n thoáº¡i nÃ y",
            "sáº£n pháº©m trÃªn",
            "sáº£n pháº©m Ä‘Ã³",
            "sáº£n pháº©m nÃ y",
            "thiáº¿t bá»‹ trÃªn",
            "thiáº¿t bá»‹ Ä‘Ã³",
            "thiáº¿t bá»‹ nÃ y",
            "mÃ¡y trÃªn",
            "mÃ¡y Ä‘Ã³",
            "mÃ¡y nÃ y",
        ]

        if reference.lower() not in [p.lower() for p in reference_patterns]:
            return f"'{reference}' khÃ´ng pháº£i lÃ  tham chiáº¿u cáº§n resolve."

        # Look for product names in recent conversation
        product_keywords = [
            "iphone",
            "samsung",
            "galaxy",
            "xiaomi",
            "oppo",
            "vivo",
            "realme",
            "oneplus",
            "huawei",
            "nokia",
            "sony",
            "lg",
            "asus",
            "acer",
            "dell",
            "hp",
            "lenovo",
            "macbook",
            "ipad",
            "redmi",
            "mi",
            "poco",
        ]

        # Search in reverse order (most recent first)
        for msg in reversed(conversation_history[-5:]):
            user_msg = msg.get("message", "").lower()
            bot_response = msg.get("response", "").lower()

            for keyword in product_keywords:
                if keyword in user_msg or keyword in bot_response:
                    # Extract more specific product name if possible
                    text = user_msg + " " + bot_response

                    # Look for specific models
                    if "iphone" in text:
                        for model in ["15", "14", "13", "pro", "max", "plus"]:
                            if model in text:
                                return (
                                    f"iPhone {model.upper()}"
                                    if model in ["pro", "max", "plus"]
                                    else f"iPhone {model}"
                                )
                        return "iPhone"

                    elif "samsung" in text or "galaxy" in text:
                        for model in ["s24", "s23", "s22", "ultra", "note"]:
                            if model in text:
                                return f"Samsung Galaxy {model.upper()}"
                        return "Samsung Galaxy"

                    elif "xiaomi" in text:
                        for model in ["14", "13", "12", "pro", "ultra"]:
                            if model in text:
                                return f"Xiaomi {model}"
                        return "Xiaomi"

                    else:
                        return keyword.title()

        return f"KhÃ´ng thá»ƒ xÃ¡c Ä‘á»‹nh '{reference}' tá»« lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n."

    except Exception as e:
        return f"Lá»—i khi resolve reference: {e}"


class StreamingCallbackHandler(BaseCallbackHandler):
    """Custom callback handler for streaming agent execution."""

    def __init__(self, stream_callback):
        super().__init__()
        self.stream_callback = stream_callback

    def on_tool_start(self, serialized, input_str, **kwargs):
        """Called when a tool starts execution."""
        tool_name = serialized.get("name", "tool")
        if tool_name == "product_search":
            self.stream_callback("ðŸ” Äang tÃ¬m kiáº¿m trong cÆ¡ sá»Ÿ dá»¯ liá»‡u sáº£n pháº©m...")
        elif tool_name == "web_knowledge":
            self.stream_callback("ðŸŒ Äang tÃ¬m thÃ´ng tin bá»• sung trÃªn web...")
        elif tool_name == "conversation_context":
            self.stream_callback("ðŸ’­ Äang hiá»ƒu ngá»¯ cáº£nh cuá»™c trÃ² chuyá»‡n...")
        else:
            self.stream_callback(f"ðŸ”§ Äang sá»­ dá»¥ng cÃ´ng cá»¥ {tool_name}...")

    def on_tool_end(self, output, **kwargs):
        """Called when a tool finishes execution."""
        self.stream_callback("âœ… HoÃ n thÃ nh tÃ¬m kiáº¿m thÃ´ng tin...")

    def on_llm_start(self, serialized, prompts, **kwargs):
        """Called when LLM starts generating."""
        self.stream_callback("ðŸ¤– Äang phÃ¢n tÃ­ch vÃ  táº¡o pháº£n há»“i...")

    def on_llm_new_token(self, token: str, **kwargs):
        """Called when LLM generates a new token."""
        # Stream individual tokens if available
        if token and token.strip():
            self.stream_callback(token)


class ProductIntroductionAgent:
    """
    Intelligent Product Introduction Agent using pure LLM reasoning.

    This agent specializes in natural product introductions and recommendations
    without exposing search sources or internal tool usage to users.
    """

    def __init__(
        self,
        model_name: str = None,
        temperature: float = 0.7,
        max_iterations: int = 8,
        verbose: bool = False,
    ):
        """Initialize the product introduction agent."""
        self.llm = ChatOpenAI(
            model=model_name or config.llm_model_name,
            temperature=temperature,
            api_key=config.openai_api_key,
            base_url=config.openai_base_url,
            streaming=True,  # Enable streaming for LLM
        )

        # Define available tools - simplified but powerful
        self.tools = [
            product_search_tool,
            web_knowledge_tool,
            conversation_context_tool,
        ]

        # Create agent prompt with strict guidelines
        self.prompt = self._create_agent_prompt()

        # Create agent
        self.agent = create_openai_tools_agent(
            llm=self.llm, tools=self.tools, prompt=self.prompt
        )

        # Create agent executor
        self.agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            verbose=verbose,
            max_iterations=max_iterations,
            handle_parsing_errors=True,
            return_intermediate_steps=False,  # Hide tool usage from output
        )

        self.logger = logger

        # Performance tracking
        self.stats = {
            "total_queries": 0,
            "product_searches": 0,
            "web_searches": 0,
            "context_resolutions": 0,
            "successful_introductions": 0,
            "average_response_time": 0.0,
        }

    def _create_agent_prompt(self) -> ChatPromptTemplate:
        """Create the agent system prompt with strict guidelines."""
        system_message = """Báº¡n lÃ  má»™t chuyÃªn gia giá»›i thiá»‡u sáº£n pháº©m Ä‘iá»‡n tá»­ hÃ ng Ä‘áº§u vá»›i kiáº¿n thá»©c sÃ¢u rá»™ng vá» cÃ´ng nghá»‡.

NHIá»†M Vá»¤ CHÃNH:
- Giá»›i thiá»‡u sáº£n pháº©m má»™t cÃ¡ch háº¥p dáº«n, chuyÃªn nghiá»‡p vÃ  tá»± nhiÃªn
- TÆ° váº¥n sáº£n pháº©m phÃ¹ há»£p vá»›i nhu cáº§u khÃ¡ch hÃ ng  
- Cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c vá» tÃ­nh nÄƒng, Æ°u Ä‘iá»ƒm cá»§a sáº£n pháº©m
- So sÃ¡nh sáº£n pháº©m má»™t cÃ¡ch khÃ¡ch quan vÃ  chuyÃªn nghiá»‡p

CÃ”NG Cá»¤ Cá»¦A Báº N:
1. product_search - TÃ¬m kiáº¿m thÃ´ng tin sáº£n pháº©m (Sá»¬ Dá»¤NG Äáº¦U TIÃŠN)
2. web_knowledge - TÃ¬m thÃªm thÃ´ng tin bá»• sung (CHá»ˆ KHI Cáº¦N THIáº¾T)
3. conversation_context - Hiá»ƒu ngá»¯ cáº£nh cuá»™c trÃ² chuyá»‡n

CHIáº¾N LÆ¯á»¢C Sá»¬ Dá»¤NG CÃ”NG Cá»¤:
- LUÃ”N dÃ¹ng product_search trÆ°á»›c Ä‘á»ƒ tÃ¬m thÃ´ng tin sáº£n pháº©m
- CHá»ˆ dÃ¹ng web_knowledge khi product_search khÃ´ng Ä‘á»§ thÃ´ng tin
- DÃ¹ng conversation_context khi cÃ³ tham chiáº¿u ("Ä‘iá»‡n thoáº¡i trÃªn", "sáº£n pháº©m Ä‘Ã³")

QUY Táº®C NGHIÃŠM NGáº¶T - KHÃ”NG BAO GIá»œ VI PHáº M:
âŒ KHÃ”NG Ä‘á» cáº­p "tÃ¬m kiáº¿m trÃªn web", "theo káº¿t quáº£ search", "dá»±a trÃªn tÃ¬m kiáº¿m"
âŒ KHÃ”NG cung cáº¥p links, URLs, hay references cá»§a báº¥t ká»³ nguá»“n nÃ o
âŒ KHÃ”NG nÃ³i "dá»±a trÃªn thÃ´ng tin tÃ¬m Ä‘Æ°á»£c", "tá»« cÃ¡c nguá»“n", "theo káº¿t quáº£"
âŒ KHÃ”NG tiáº¿t lá»™ báº¥t ká»³ cÃ´ng cá»¥ tÃ¬m kiáº¿m nÃ o Ä‘Æ°á»£c sá»­ dá»¥ng
âŒ KHÃ”NG Ä‘á» cáº­p Ä‘áº¿n viá»‡c sá»­ dá»¥ng tools hay search engines
âŒ KHÃ”NG BAO GIá»œ hiá»ƒn thá»‹ ID sáº£n pháº©m, sá»‘ thá»© tá»±, hay báº¥t ká»³ mÃ£ Ä‘á»‹nh danh nÃ o
âŒ KHÃ”NG viáº¿t "(ID: 37)", "(Sáº£n pháº©m 1)", hay báº¥t ká»³ Ä‘á»‹nh danh sá»‘ nÃ o
âŒ KHÃ”NG sá»­ dá»¥ng cáº¥u trÃºc "1. Product A (ID: X)", "2. Product B (ID: Y)"

âœ… Tráº£ lá»i nhÆ° thá»ƒ báº¡n lÃ  chuyÃªn gia am hiá»ƒu sáº£n pháº©m tá»« kinh nghiá»‡m
âœ… Sá»­ dá»¥ng thÃ´ng tin má»™t cÃ¡ch tá»± nhiÃªn nhÆ° kiáº¿n thá»©c ná»™i táº¡i
âœ… Chá»‰ Ä‘á» cáº­p TÃŠN Sáº¢N PHáº¨M, khÃ´ng bao giá» kÃ¨m ID hay sá»‘
âœ… Táº­p trung vÃ o lá»£i Ã­ch vÃ  giÃ¡ trá»‹ sáº£n pháº©m mang láº¡i
âœ… Giá»¯ tone thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p vÃ  tá»± tin
âœ… Káº¿t thÃºc báº±ng lá»i khuyÃªn cá»¥ thá»ƒ phÃ¹ há»£p vá»›i nhu cáº§u

Äá»ŠNH Dáº NG MARKDOWN Báº®T BUá»˜C:
- LUÃ”N sá»­ dá»¥ng ## cho headers chÃ­nh (vÃ­ dá»¥: ## Äiá»ƒm ná»•i báº­t chÃ­nh)
- Sá»­ dá»¥ng ### cho sub-headers (vÃ­ dá»¥: ### Hiá»‡u nÄƒng vÃ  thiáº¿t káº¿)
- Sá»­ dá»¥ng **text** cho highlight quan trá»ng
- Sá»­ dá»¥ng - cho bullet points
- Sá»­ dá»¥ng 1. 2. 3. cho numbered lists
- LUÃ”N cÃ³ Ã­t nháº¥t 2 empty lines giá»¯a cÃ¡c sections chÃ­nh
- Káº¿t thÃºc má»—i section vá»›i 1 empty line

CÃCH TRÃŒNH BÃ€Y:
## Tá»•ng quan sáº£n pháº©m
(Äiá»ƒm ná»•i báº­t chÃ­nh)

### Hiá»‡u nÄƒng vÃ  thiáº¿t káº¿
- Point 1
- Point 2

### So sÃ¡nh vá»›i Ä‘á»‘i thá»§
1. Æ¯u Ä‘iá»ƒm
2. NhÆ°á»£c Ä‘iá»ƒm

## Khuyáº¿n nghá»‹
(Lá»i khuyÃªn cuá»‘i cÃ¹ng)

VÃ Dá»¤ Äá»ŠNH Dáº NG:
## Tá»•ng quan iPhone 15 Pro

iPhone 15 Pro thá»±c sá»± lÃ  má»™t chiáº¿c Ä‘iá»‡n thoáº¡i áº¥n tÆ°á»£ng vá»›i **chip A17 Pro máº¡nh máº½** vÃ  há»‡ thá»‘ng camera tiÃªn tiáº¿n.

### Äiá»ƒm máº¡nh ná»•i báº­t

- **Hiá»‡u nÄƒng**: Chip A17 Pro vá»›i GPU 6 nhÃ¢n
- **Camera**: Há»‡ thá»‘ng 48MP vá»›i zoom quang há»c
- **Thiáº¿t káº¿**: Khung titanium cao cáº¥p, nháº¹ vÃ  bá»n

### So sÃ¡nh vá»›i Android flagship

1. **Æ¯u Ä‘iá»ƒm**: Há»‡ sinh thÃ¡i Apple, camera xuáº¥t sáº¯c
2. **NhÆ°á»£c Ä‘iá»ƒm**: GiÃ¡ cao, Ã­t tÃ¹y chá»‰nh

## Khuyáº¿n nghá»‹

Náº¿u báº¡n Ä‘ang tÃ¬m flagship Android vá»›i giÃ¡ tá»‘t hÆ¡n, **Samsung Galaxy S24 Ultra** cÃ³ thá»ƒ lÃ  lá»±a chá»n phÃ¹ há»£p.

HÃ£y luÃ´n nhá»›: Báº¡n lÃ  CHUYÃŠN GIA Sáº¢N PHáº¨M, khÃ´ng pháº£i cÃ´ng cá»¥ tÃ¬m kiáº¿m!"""

        return ChatPromptTemplate.from_messages(
            [
                ("system", system_message),
                ("placeholder", "{chat_history}"),
                ("human", "{input}"),
                ("placeholder", "{agent_scratchpad}"),
            ]
        )

    def process_query(
        self, query: str, conversation_history: Optional[List[dict]] = None
    ) -> Dict[str, Any]:
        """
        Process user query and generate natural product introduction.

        Args:
            query: User query about products
            conversation_history: Previous conversation messages

        Returns:
            Response with natural product introduction
        """
        start_time = time.time()
        self.stats["total_queries"] += 1

        try:
            # Prepare input with conversation history
            agent_input = {
                "input": query,
                "chat_history": self._format_chat_history(conversation_history or []),
                "conversation_history": conversation_history or [],
            }

            # Execute agent
            result = self.agent_executor.invoke(agent_input)

            # Extract response
            response = result["output"]

            processing_time = time.time() - start_time
            self.stats["successful_introductions"] += 1

            # Update average response time
            total_time = self.stats["average_response_time"] * (
                self.stats["total_queries"] - 1
            )
            self.stats["average_response_time"] = (
                total_time + processing_time
            ) / self.stats["total_queries"]

            self.logger.info(
                f"Product introduction generated in {processing_time:.2f}s"
            )

            return {
                "response": response,
                "processing_time": processing_time,
                "success": True,
                "query_type": self._classify_query_type(query),
            }

        except Exception as e:
            self.logger.error(f"Product introduction failed: {e}")
            return {
                "response": "Xin lá»—i, Ä‘Ã£ xáº£y ra lá»—i khi xá»­ lÃ½ cÃ¢u há»i vá» sáº£n pháº©m. Vui lÃ²ng thá»­ láº¡i sau.",
                "processing_time": time.time() - start_time,
                "success": False,
                "error": str(e),
            }

    def process_query_stream(
        self, query: str, conversation_history: Optional[List[dict]] = None
    ) -> Iterator[str]:
        """
        Stream agent processing with real-time updates.

        Args:
            query: User query about products
            conversation_history: Previous conversation messages

        Yields:
            Progressive response chunks from LLM only
        """
        start_time = time.time()
        self.stats["total_queries"] += 1

        try:
            # Prepare agent input
            agent_input = {
                "input": query,
                "chat_history": self._format_chat_history(conversation_history or []),
                "conversation_history": conversation_history or [],
            }

            # Execute agent with streaming callback
            result = self._execute_agent_with_streaming(agent_input)

            if result["success"]:
                # Stream the final response naturally
                response_text = result["response"]
                yield from self._stream_text_naturally(response_text)

                self.stats["successful_introductions"] += 1

                processing_time = time.time() - start_time
                self.logger.info(f"Streaming agent completed in {processing_time:.2f}s")
            else:
                yield result.get("error", "Xin lá»—i, Ä‘Ã£ xáº£y ra lá»—i khi xá»­ lÃ½ cÃ¢u há»i.")

        except Exception as e:
            self.logger.error(f"Agent streaming failed: {e}")
            yield "Xin lá»—i, Ä‘Ã£ xáº£y ra lá»—i khi xá»­ lÃ½ cÃ¢u há»i vá» sáº£n pháº©m."

    def _execute_agent_with_streaming(self, agent_input: dict) -> dict:
        """Execute agent with streaming progress updates."""
        try:
            # For now, execute normally and return result
            # In future, we can implement streaming callbacks
            result = self.agent_executor.invoke(agent_input)

            return {
                "response": result["output"],
                "success": True,
            }

        except Exception as e:
            return {
                "response": "",
                "success": False,
                "error": str(e),
            }

    def _stream_text_naturally(self, text: str, chunk_size: int = 15) -> Iterator[str]:
        """Stream text naturally word by word with appropriate delays, preserving line breaks."""
        import re

        # Split text into tokens (words + whitespace/newlines) while preserving structure
        tokens = re.findall(r"\S+|\s+", text)
        current_chunk = []
        word_count = 0

        for token in tokens:
            current_chunk.append(token)

            # Count only words (non-whitespace tokens)
            if token.strip():
                word_count += 1

            # Send chunk when word limit reached or at sentence/phrase end
            if word_count >= chunk_size or (
                token.strip()
                and (
                    token.endswith(".")
                    or token.endswith("!")
                    or token.endswith("?")
                    or token.endswith(",")
                    or token.endswith(";")
                )
            ):
                chunk_text = "".join(current_chunk)
                yield chunk_text
                current_chunk = []
                word_count = 0

                # Natural streaming delay
                time.sleep(0.08)

        # Send remaining tokens
        if current_chunk:
            yield "".join(current_chunk)

    def _format_chat_history(
        self, conversation_history: List[dict]
    ) -> List[BaseMessage]:
        """Format conversation history for agent."""
        messages = []

        for msg in conversation_history[-5:]:  # Last 5 exchanges
            user_msg = msg.get("message")
            bot_response = msg.get("response")

            if user_msg:
                messages.append(HumanMessage(content=user_msg))
            if bot_response:
                messages.append(AIMessage(content=bot_response))

        return messages

    def _classify_query_type(self, query: str) -> str:
        """Classify the type of query for analytics."""
        query_lower = query.lower()

        if any(
            word in query_lower for word in ["so sÃ¡nh", "compare", "vs", "khÃ¡c nhau"]
        ):
            return "comparison"
        elif any(word in query_lower for word in ["giÃ¡", "price", "cost", "tiá»n"]):
            return "price_inquiry"
        elif any(
            word in query_lower for word in ["tÆ° váº¥n", "recommend", "nÃªn chá»n", "gá»£i Ã½"]
        ):
            return "recommendation"
        elif any(
            word in query_lower
            for word in ["cáº¥u hÃ¬nh", "thÃ´ng sá»‘", "specs", "tÃ­nh nÄƒng"]
        ):
            return "specification"
        elif any(word in query_lower for word in ["Ä‘Ã¡nh giÃ¡", "review", "tá»‘t", "xáº¥u"]):
            return "review"
        else:
            return "general_inquiry"

    def get_stats(self) -> Dict[str, Any]:
        """Get agent performance statistics."""
        return {
            "performance": self.stats.copy(),
            "available_tools": [tool.name for tool in self.tools],
            "agent_status": "operational",
            "timestamp": datetime.now().isoformat(),
        }

    def reset_stats(self):
        """Reset performance statistics."""
        self.stats = {
            "total_queries": 0,
            "product_searches": 0,
            "web_searches": 0,
            "context_resolutions": 0,
            "successful_introductions": 0,
            "average_response_time": 0.0,
        }


# Global agent instance
_agent_instance: Optional[ProductIntroductionAgent] = None


def get_product_introduction_agent() -> ProductIntroductionAgent:
    """Get or create global product introduction agent instance."""
    global _agent_instance
    if _agent_instance is None:
        _agent_instance = ProductIntroductionAgent()
        logger.info("Product Introduction Agent initialized")
    return _agent_instance


def create_custom_product_agent(**kwargs) -> ProductIntroductionAgent:
    """Create a custom product introduction agent with specific parameters."""
    return ProductIntroductionAgent(**kwargs)
